#!/usr/bin/env python3
"""
Twitter Scraper with AI Analysis

Main entry point for scraping Twitter data and analyzing cryptocurrency 
trading signals using Ollama AI with optional position simulation.
"""

# Standard library imports
import argparse
import json
import os
import sys
from typing import Optional

# Local application imports
try:
    # Try relative imports when run as module
    from .models_logic import process_tweets_with_ollama
except ImportError:
    # Fallback for direct execution
    from models_logic import process_tweets_with_ollama


def load_env_file() -> None:
    """Load environment variables from .env file."""
    env_path = os.path.join(os.path.dirname(__file__), '.env')
    if os.path.exists(env_path):
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                if '=' in line and not line.strip().startswith('#'):
                    key, value = line.strip().split('=', 1)
                    os.environ[key] = value


def run_and_print(
    user: str,
    limit: int,
    model: str,
    system_msg: Optional[str],
    as_json: bool,
    mock_scraping: bool,
    mock_positions: bool,
    use_tools: bool = True,
    calculate_positions: bool = False,
    simulate_positions: bool = False,
    simulation_hours: int = 24,
    api_provider: str = "coincap",
    validate_sentiment: bool = False
) -> Optional[dict]:
    """
    Main function to run tweet analysis and optionally simulate positions.
    
    Args:
        user: Twitter username or handle
        limit: Number of tweets to analyze
        model: Ollama model name
        system_msg: Custom system instruction
        as_json: Output in JSON format
        mock_scraping: Use mock tweets
        mock_positions: Use mock prices for simulation
        use_tools: Enable AI tools
        calculate_positions: Calculate trading positions
        simulate_positions: Simulate position performance
        simulation_hours: Hours to simulate
        
    Returns:
        dict: Consolidated analysis with validation results (if available)
    """
    # Load environment variables
    load_env_file()
    
    # Process tweets with AI analysis
    results = process_tweets_with_ollama(
        user, limit, model, 
        system_instruction=system_msg, 
        mock=mock_scraping, 
        use_tools=use_tools
    )
    
    if as_json:
        print(json.dumps(results, indent=2, ensure_ascii=False))
        return None
    
    # Format output for console display and get structured result
    structured_result = _display_results(results, calculate_positions, simulate_positions, mock_positions, api_provider, validate_sentiment, model, system_msg)
    
    return structured_result


def _display_results(
    results: list,
    calculate_positions: bool,
    simulate_positions: bool,
    mock_positions: bool,
    api_provider: str = "coincap",
    validate_sentiment: bool = False,
    model: str = "qwen3:14b",
    system_msg: Optional[str] = None
) -> Optional[dict]:
    """Display results in formatted console output and return structured data."""
    print("\n" + "üê¶" * 20 + " CONTENU DES TWEETS " + "üê¶" * 20)
    
    # Separate individual tweets from consolidated analysis
    tweet_results = [r for r in results if "consolidated_analysis" not in r]
    consolidated = next((r for r in results if "consolidated_analysis" in r), None)
    
    # Display tweet content only
    for i, tweet_result in enumerate(tweet_results, start=1):
        tweet_text = tweet_result.get('full_text', '')
        if len(tweet_text) > 300:
            tweet_text = tweet_text[:300] + "..."
        print(f"\nüìù TWEET #{i}: {tweet_text}")
    
    # Display consolidated analysis
    if consolidated:
        print("\n" + "üìä" * 20 + " ANALYSE CONSOLID√âE " + "üìä" * 20)
        cons_data = consolidated["consolidated_analysis"]
        print(json.dumps(cons_data, indent=2, ensure_ascii=False))
        
        # Calculate positions if requested
        if calculate_positions:
            _handle_position_calculation(cons_data)
        
        # Simulate positions if requested
        if simulate_positions:
            _handle_position_simulation(cons_data, mock_positions, api_provider)
        
        # Validate sentiment predictions if requested
        if validate_sentiment:
            validation_data = _handle_sentiment_validation(cons_data, mock_positions)
            # Add validation results to consolidated data
            cons_data["sentiment_validation"] = validation_data
            
            # Display final analysis summary
            _display_final_analysis_summary(cons_data)
        
        # Final Ollama analysis of all collected data
        _handle_final_ollama_analysis(cons_data, model, system_msg)
        
        print("\n" + "üèÅ" * 10 + " FIN DE L'ANALYSE " + "üèÅ" * 10)
        
        # Return the consolidated data with all results
        return cons_data
    
    print("\n" + "üèÅ" * 10 + " FIN DE L'ANALYSE " + "üèÅ" * 10)
    return None


def _handle_position_calculation(consolidated_data: dict) -> None:
    """Handle position calculation."""
    try:
        try:
            from .coincap_api import calculate_positions, display_positions_summary
        except ImportError:
            from coincap_api import calculate_positions, display_positions_summary
        positions_result = calculate_positions(consolidated_data)
        display_positions_summary(positions_result)
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors du calcul des positions: {e}")
        print("üí° Assurez-vous d'avoir configur√© COINCAP_API_KEY dans .env")


def _handle_position_simulation(consolidated_data: dict, mock_positions: bool, api_provider: str = "coincap") -> None:
    """Handle position simulation."""
    try:
        # Configure API based on provider choice
        if api_provider == "coingecko":
            try:
                from .api_manager import create_api_manager, APIProvider
            except ImportError:
                from api_manager import create_api_manager, APIProvider
            
            # Use CoinGecko with CoinCap fallback
            api_manager = create_api_manager({
                "primary_api": APIProvider.COINGECKO,
                "enable_fallback": True,
                "mock_mode": mock_positions
            })
            simulator = api_manager.create_simulator()
            print("ü¶é Utilisation de CoinGecko API pour la simulation")
        else:
            # Default CoinCap
            try:
                from .coincap_api import PositionSimulator
            except ImportError:
                from coincap_api import PositionSimulator
            simulator = PositionSimulator(mock_mode=mock_positions)
            print("üìä Utilisation de CoinCap API pour la simulation")
        
        simulation_result = simulator.simulate_all_positions(consolidated_data)
        
        if "error" not in simulation_result:
            print("\n" + "üéØ" * 20 + " R√âSULTATS PERFORMANCES " + "üéØ" * 20)
            print(f"üí∞ Capital total: ${simulation_result['total_capital']:.2f}")
            print(f"üìà P&L total: {simulation_result['total_pnl']:+.2f}$")
            print(f"üìä ROI: {simulation_result['roi_percent']:+.2f}%")
        else:
            print(f"‚ùå Erreur simulation: {simulation_result['error']}")
            
    except (ImportError, ValueError, TypeError) as e:
        print(f"‚ö†Ô∏è Erreur lors de la simulation: {e}")
        if not mock_positions:
            api_key_name = "COINGECKO_API_KEY" if api_provider == "coingecko" else "COINCAP_API_KEY"
            print(f"üí° Assurez-vous d'avoir configur√© {api_key_name} dans .env")
        else:
            print("üí° Erreur en mode mock positions")


def _handle_sentiment_validation(consolidated_data: dict, mock_mode: bool = False) -> dict:
    """Handle sentiment validation over time and return results."""
    print("\n" + "‚è∞" * 20 + " VALIDATION TEMPORELLE " + "‚è∞" * 20)
    
    try:
        try:
            from .coingecko_api.sentiment_validator import SentimentValidator
        except ImportError:
            from coingecko_api.sentiment_validator import SentimentValidator
        
        # Initialize validator with mock mode option
        validator = SentimentValidator(mock_mode=mock_mode)
        
        # Extract sentiment data with timestamps from consolidated analysis
        sentiment_data_list = []
        
        # Convert consolidated analysis to format expected by validator
        tweets_analysis = consolidated_data.get("tweets_analysis", [])
        if not tweets_analysis:
            # Fallback: try to extract from consolidated_data if it's a list
            if isinstance(consolidated_data, list):
                for analysis in consolidated_data:
                    if isinstance(analysis, dict):
                        sentiment_data = {
                            "ticker": analysis.get("ticker", ""),
                            "sentiment": analysis.get("sentiment", "neutral"),
                            "context": analysis.get("context", ""),
                            "timestamp": analysis.get("timestamp", "2025-01-01T00:00:00Z")
                        }
                        sentiment_data_list.append(sentiment_data)
        else:
            # Standard format from consolidated analysis
            for analysis in tweets_analysis:
                if isinstance(analysis, dict):
                    sentiment_data = {
                        "ticker": analysis.get("ticker", ""),
                        "sentiment": analysis.get("sentiment", "neutral"),
                        "context": analysis.get("context", ""),
                        "timestamp": analysis.get("timestamp", "2025-01-01T00:00:00Z")
                    }
                    sentiment_data_list.append(sentiment_data)
        
        if not sentiment_data_list:
            print("‚ùå Aucune donn√©e de sentiment trouv√©e pour la validation")
            return {
                "validation_status": "error",
                "error_message": "Aucune donn√©e de sentiment trouv√©e",
                "results": {}
            }
        
        # Validate all sentiments
        validation_results = validator.validate_all_sentiments(sentiment_data_list)
        
        # Display results
        print(f"\nüìä Statistiques globales:")
        stats = validation_results["global_stats"]
        total = stats["total_predictions"]
        
        if total > 0:
            print(f"   Total pr√©dictions: {total}")
            print(f"   Pr√©cision 1h:  {stats['correct_1h']}/{total} ({stats['correct_1h']/total*100:.1f}%)")
            print(f"   Pr√©cision 24h: {stats['correct_24h']}/{total} ({stats['correct_24h']/total*100:.1f}%)")
            print(f"   Pr√©cision 7j:  {stats['correct_7d']}/{total} ({stats['correct_7d']/total*100:.1f}%)")
            print(f"   Score moyen 1h:  {stats['avg_accuracy_1h']:.1f}/100")
            print(f"   Score moyen 24h: {stats['avg_accuracy_24h']:.1f}/100")
            print(f"   Score moyen 7j:  {stats['avg_accuracy_7d']:.1f}/100")
        
        # Also display detailed results for each prediction
        print(f"\nüîç D√©tails par pr√©diction:")
        for result in validation_results["validation_results"]:
            ticker = result["ticker"]
            sentiment = result["sentiment"]
            base_price = result.get("base_price", 0)
            
            print(f"\nü™ô {ticker} ({sentiment}) - Base: ${base_price:.2f}")
            validations = result.get("validations", {})
            for period, validation in validations.items():
                if "error" in validation:
                    print(f"   {period:>3}: ‚ö†Ô∏è  {validation['error']}")
                else:
                    correct = "‚úÖ" if validation.get("correct", False) else "‚ùå"
                    price_change = validation.get("price_change_pct", 0)
                    actual = validation.get("actual_direction", "unknown")
                    score = validation.get("accuracy_score", 0)
                    print(f"   {period:>3}: {correct} {price_change:+.2f}% (Score: {score:.0f})")
        
        # Return structured results
        return {
            "validation_status": "success",
            "global_stats": validation_results["global_stats"],
            "validation_results": validation_results["validation_results"],
            "summary": {
                "total_predictions": total,
                "accuracy_1h_percent": stats['correct_1h']/total*100 if total > 0 else 0,
                "accuracy_24h_percent": stats['correct_24h']/total*100 if total > 0 else 0,
                "accuracy_7d_percent": stats['correct_7d']/total*100 if total > 0 else 0,
                "avg_score_1h": stats['avg_accuracy_1h'],
                "avg_score_24h": stats['avg_accuracy_24h'],
                "avg_score_7d": stats['avg_accuracy_7d']
            }
        }
        
    except (ImportError, ValueError, TypeError) as e:
        print(f"‚ö†Ô∏è Erreur lors de la validation de sentiment: {e}")
        if not mock_mode:
            print("üí° Assurez-vous d'avoir configur√© COINGECKO_API_KEY dans .env pour l'historique des prix")
        else:
            print("üí° Erreur en mode mock de validation")
        
        return {
            "validation_status": "error",
            "error_message": str(e),
            "results": {}
        }


def _display_final_analysis_summary(consolidated_data: dict) -> None:
    """Display a comprehensive final analysis of influencer predictions and their validation."""
    print("\n" + "üéØ" * 20 + " ANALYSE FINALE DES PR√âDICTIONS " + "üéØ" * 20)
    
    account = consolidated_data.get("account", "Compte inconnu")
    total_tweets = consolidated_data.get("total_tweets", 0)
    
    print(f"üë§ Influenceur analys√©: {account}")
    print(f"üìä Nombre de tweets analys√©s: {total_tweets}")
    
    # Analysis summary
    analysis_summary = consolidated_data.get("analysis_summary", {})
    print(f"\nüìà R√©sum√© des sentiments d√©tect√©s:")
    print(f"   üü¢ Bullish: {analysis_summary.get('bullish_sentiments', 0)}")
    print(f"   üî¥ Bearish: {analysis_summary.get('bearish_sentiments', 0)}")
    print(f"   ‚ö™ Neutral: {analysis_summary.get('neutral_sentiments', 0)}")
    
    # Validation results
    sentiment_validation = consolidated_data.get("sentiment_validation", {})
    if sentiment_validation and sentiment_validation.get("validation_status") == "success":
        print(f"\nüîç Validation temporelle des pr√©dictions:")
        
        summary = sentiment_validation.get("summary", {})
        total_predictions = summary.get("total_predictions", 0)
        
        if total_predictions > 0:
            print(f"   ‚è∞ Pr√©cision √† 1h:  {summary.get('accuracy_1h_percent', 0):.1f}%")
            print(f"   ‚è∞ Pr√©cision √† 24h: {summary.get('accuracy_24h_percent', 0):.1f}%")
            print(f"   ‚è∞ Pr√©cision √† 7j:  {summary.get('accuracy_7d_percent', 0):.1f}%")
            
            # Detailed analysis for each prediction
            validation_results = sentiment_validation.get("validation_results", [])
            
            print(f"\nüî¨ Analyse d√©taill√©e par annonce:")
            for i, result in enumerate(validation_results, 1):
                ticker = result.get("ticker", "N/A")
                sentiment = result.get("sentiment", "neutral")
                context = result.get("context", "Aucun contexte")
                timestamp = result.get("timestamp", "")
                base_price = result.get("base_price", 0)
                
                # Format timestamp
                formatted_time = ""
                if timestamp:
                    try:
                        from datetime import datetime
                        dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                        formatted_time = dt.strftime("%d/%m/%Y √† %H:%M")
                    except:
                        formatted_time = timestamp[:16]
                
                print(f"\n   üìù Tweet #{i} - {ticker}")
                print(f"      üïê Date: {formatted_time}")
                print(f"      üí≠ Sentiment pr√©dit: {sentiment}")
                print(f"      üí° Contexte: {context}")
                print(f"      üí∞ Prix de base: ${base_price:.4f}")
                
                # Validation details
                validations = result.get("validations", {})
                for period in ["1h", "24h", "7d"]:
                    if period in validations:
                        validation = validations[period]
                        if "error" not in validation:
                            price_change = validation.get("price_change_pct", 0)
                            actual_direction = validation.get("actual_direction", "unknown")
                            correct = validation.get("correct", False)
                            accuracy_score = validation.get("accuracy_score", 0)
                            
                            status_emoji = "‚úÖ" if correct else "‚ùå"
                            direction_emoji = {"bullish": "üìà", "bearish": "üìâ", "neutral": "‚û°Ô∏è"}.get(actual_direction, "‚ùì")
                            
                            print(f"      {period:>3}: {status_emoji} {price_change:+.2f}% {direction_emoji} (Score: {accuracy_score:.0f}/100)")
                        else:
                            print(f"      {period:>3}: ‚ö†Ô∏è {validation.get('error', 'Erreur inconnue')}")
            
            # Overall performance assessment
            avg_accuracy_24h = summary.get("accuracy_24h_percent", 0)
            avg_score_24h = summary.get("avg_score_24h", 0)
            
            print(f"\nüìä √âvaluation globale de l'influenceur:")
            if avg_accuracy_24h >= 70:
                performance = "üåü Excellente"
            elif avg_accuracy_24h >= 50:
                performance = "üëç Bonne"
            elif avg_accuracy_24h >= 30:
                performance = "‚ö†Ô∏è Moyenne"
            else:
                performance = "üëé Faible"
            
            print(f"   üéØ Performance globale (24h): {performance} ({avg_accuracy_24h:.1f}%)")
            print(f"   üìà Score moyen de pr√©cision: {avg_score_24h:.1f}/100")
            
            # Recommendations
            print(f"\nüí° Recommandations:")
            if avg_accuracy_24h >= 60:
                print(f"   ‚ú® Cet influenceur montre de bonnes capacit√©s pr√©dictives")
                print(f"   ‚ú® Ses analyses peuvent √™tre consid√©r√©es comme fiables")
            elif avg_accuracy_24h >= 40:
                print(f"   ‚öñÔ∏è Performance mod√©r√©e, √† utiliser avec prudence")
                print(f"   ‚öñÔ∏è Croiser avec d'autres sources d'analyse")
            else:
                print(f"   ‚ö†Ô∏è Faible performance pr√©dictive observ√©e")
                print(f"   ‚ö†Ô∏è Recommand√© d'√™tre tr√®s prudent avec ces signaux")
        
        else:
            print("   ‚ùå Aucune pr√©diction √† valider")
    
    else:
        print(f"\n‚ùå Validation des sentiments non disponible ou √©chou√©e")
    
    print("\n" + "üéØ" * 60)
    
    # Don't display the dictionary again here - it will be shown after Ollama analysis


def _handle_final_ollama_analysis(consolidated_data: dict, model: str = "qwen3:14b", system_msg: Optional[str] = None) -> None:
    """Send the complete analysis to Ollama for final interpretation and insights."""
    print("\n" + "ü§ñ" * 20 + " ANALYSE FINALE PAR OLLAMA " + "ü§ñ" * 20)
    
    try:
        # Import Ollama functions
        try:
            from .models_logic.ollama_logic import generate_with_ollama
        except ImportError:
            from models_logic.ollama_logic import generate_with_ollama
        
        # Create analysis prompt
        analysis_prompt = f"""
{system_msg or 'Tu es un expert analyste crypto avec un sens de l\'humour qui s\'adresse √† la communaut√© crypto.'}

Tu es un analyste crypto qui parle √† des crypto-bros. Sois concis, direct et un peu sarcastique.

DONN√âES D'ANALYSE:
{json.dumps(consolidated_data, indent=2, ensure_ascii=False)}

INSTRUCTIONS:
Analyse ces donn√©es et donne un compte-rendu COURT (max 200 mots) avec:

ÔøΩ **LE DEAL**: Qui c'est et qu'est-ce qu'il predict
üéØ **SES SKILLS**: Il a vis√© juste ou il s'est plant√© ? (pr√©cision %)  
ÔøΩ **VERDICT FINAL**: DYOR ou "trust me bro" ?

Style: Ton de la crypto Twitter, un peu moqueur mais informatif. 
Utilise le jargon crypto (moon, dump, ape, diamond hands, etc.).
Reste factuel mais amusant. Pas plus de 3-4 phrases par section.
        """
        
        print("üß† G√©n√©ration de l'analyse finale par Ollama...")
        print("üìä Traitement des donn√©es collect√©es...")
        
        # Get final analysis from Ollama
        final_analysis = generate_with_ollama(
            model=model,
            prompt=analysis_prompt
        )
        
        print("\n" + "üí¨" * 60)
        print("ü§ñ ANALYSE FINALE D'OLLAMA:")
        print("üí¨" * 60)
        print(final_analysis)
        print("üí¨" * 60)
        
        # Display the complete dictionary after Ollama analysis
        print("\n" + "üìÑ" * 15 + " DICTIONNAIRE FINAL COMPLET " + "üìÑ" * 15)
        print("üîß Donn√©es compl√®tes utilis√©es pour l'analyse:")
        print(json.dumps(consolidated_data, indent=2, ensure_ascii=False))
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de l'analyse finale par Ollama: {e}")
        print("üîÑ Affichage du dictionnaire sans analyse Ollama:")
        
        # Fallback: just display the dictionary
        print("\n" + "üìÑ" * 15 + " DICTIONNAIRE FINAL COMPLET " + "üìÑ" * 15)
        print("üîß Dictionnaire structur√© pour utilisation programmatique:")
        print(json.dumps(consolidated_data, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    prompt = "You are a crypto sentiment analyst. Analyze cryptocurrency sentiment from social media posts and detect if influencers are bullish, bearish, or neutral on specific cryptocurrencies."

    parser = argparse.ArgumentParser(description="Analyze crypto sentiment in posts and validate influencer predictions over time.")
    parser.add_argument("user", nargs="?", default="swissborg", help="Twitter numeric user_id or handle (e.g., 44196397 or @elonmusk)")
    parser.add_argument("--limit", type=int, default=2, help="Number of posts to fetch")
    parser.add_argument("--model", type=str, default="qwen3:14b", help="Ollama model name/tag")
    parser.add_argument("--system", type=str, default=prompt, help="Optional system instruction to prepend")
    parser.add_argument("--json", action="store_true", help="Output JSON instead of pretty text")
    parser.add_argument("--mock-scraping", action="store_true", help="Fetch posts in mock mode (no API calls)")
    parser.add_argument("--mock-positions", action="store_true", help="Use mock mode for position simulation (no CoinCap API calls)")
    parser.add_argument("--mock", action="store_true", help="Enable both mock scraping and mock positions")
    parser.add_argument("--no-tools", action="store_true", help="Disable tools usage (legacy mode)")
    parser.add_argument("--positions", action="store_true", help="Calculate trading positions with CoinCap API")
    parser.add_argument("--simulate", action="store_true", help="Simulate trading positions with historical prices")
    parser.add_argument("--validate-sentiment", action="store_true", help="Validate sentiment predictions over time (1h, 24h, 7d)")
    parser.add_argument("--sim-hours", type=int, default=24, help="Hours to simulate (default: 24)")
    parser.add_argument("--api", type=str, choices=["coincap", "coingecko"], default="coincap", help="Cryptocurrency API to use (default: coincap)")
    parser.add_argument("--menu", action="store_true", help="Launch interactive menu")
    args = parser.parse_args()

    if args.menu or not args.user:
        # Interactive menu mode
        user = args.user or ""
        limit = args.limit
        model = args.model
        system_msg = args.system
        
        while True:
            print("\n=== Ollama Tweet Analyzer ===")
            print(f"1) Set user/handle          : {user or '(not set)'}")
            print(f"2) Set limit                : {limit}")
            print(f"3) Set model                : {model}")
            print(f"4) Set system instruction   : {system_msg or '(none)'}")
            print("5) Run analysis (pretty)")
            print("6) Run analysis (JSON)")
            print("7) Quit")
            
            choice = input("> ").strip()
            
            if choice == "1":
                user = input("Enter user_id or handle (@handle): ").strip()
            elif choice == "2":
                try:
                    limit = int(input("Enter limit (e.g., 10): ").strip())
                except ValueError:
                    print("Invalid number")
            elif choice == "3":
                model = input("Enter Ollama model (e.g., llama3.1:8b): ").strip() or model
            elif choice == "4":
                system_msg = input("Enter system instruction (optional): ").strip() or None
            elif choice == "5":
                if not user:
                    print("Please set a user/handle first.")
                    continue
                run_and_print(
                    user, limit, model, system_msg, 
                    as_json=False, mock_scraping=True, mock_positions=False, 
                    use_tools=not args.no_tools, calculate_positions=False, 
                    simulate_positions=False, simulation_hours=24
                )
            elif choice == "6":
                if not user:
                    print("Please set a user/handle first.")
                    continue
                run_and_print(
                    user, limit, model, system_msg, 
                    as_json=True, mock_scraping=True, mock_positions=False, 
                    use_tools=not args.no_tools, calculate_positions=False, 
                    simulate_positions=False, simulation_hours=24
                )
            elif choice == "7":
                sys.exit(0)
            else:
                print("Unknown option")
    else:
        # Direct CLI mode
        mock_scraping = args.mock_scraping or args.mock
        mock_positions = args.mock_positions or args.mock
        
        run_and_print(
            args.user, args.limit, args.model, args.system, 
            as_json=args.json, mock_scraping=mock_scraping, 
            mock_positions=mock_positions, use_tools=not args.no_tools, 
            calculate_positions=args.positions, simulate_positions=args.simulate, 
            simulation_hours=args.sim_hours, api_provider=args.api, 
            validate_sentiment=args.validate_sentiment
        )
